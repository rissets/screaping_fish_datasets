# Fish Scraper Configuration for Ubuntu Server

[logging]
level = INFO
format = %(asctime)s - %(name)s - %(levelname)s - %(message)s
file = logs/scraper.log
max_size = 10MB
backup_count = 5

[scraping]
# Default settings
min_images = 100
max_retries = 3
download_timeout = 30
concurrent_downloads = 2
delay_between_downloads = 1.5
delay_between_species = 5

[browser]
# Browser settings for Ubuntu server
headless = true
user_agent = Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36
window_size = 1280x1024
disable_gpu = true
no_sandbox = true
disable_dev_shm_usage = true

[paths]
# Directory settings
output_dir = fish_images
log_dir = logs
temp_dir = /tmp
csv_file = fish_scraping_list_updated.csv
backup_dir = backups

[server]
# Server-specific settings
virtual_display = :99
max_memory_mb = 2048
max_cpu_percent = 80
enable_monitoring = true

[api]
# API endpoints (if needed)
fishbase_api = https://fishbase.se/api/
wikipedia_api = https://en.wikipedia.org/api/rest_v1/
unsplash_api = https://api.unsplash.com/

[notifications]
# Notification settings (optional)
enable_email = false
smtp_server = smtp.gmail.com
smtp_port = 587
email_from = scraper@example.com
email_to = admin@example.com

# Webhook for completion notifications
webhook_url = 
webhook_enabled = false